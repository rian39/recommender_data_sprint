---
title: 'Controversiality Data Sprint'
output: 'powerpoint_presentation'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(cache = TRUE)
```

# Reading Robs zip file from GoogleDrive

```{r data-wrangling,warning = FALSE, message = FALSE, cache = TRUE}

library(readr)
library(tidyverse)
library(digest)

# to read multiple tables - this was my first attempt -- probably redundant now
# it doesn't really work
readrawdata  <-  function(path) {
    futbl <-
        list.files(path, pattern='*comments.csv', recursive = TRUE) %>%
        map_df(~read_csv(.))
    return(futbl)
}

# Galens import function
# list all files in dirs (and subdirs) ending in comments.csv
raw_comment_files <- list.files(path = "./data",
                                pattern = "*comments.csv",
                                recursive = TRUE)

# prepend ./data/ to the file paths (because I'm storing the data in ./data/)
for (i in 1:length(raw_comment_files)) {
  raw_comment_files[i] <- paste0("./data/",raw_comment_files[i])
}

# function to read csv and join a filename column
# also made a new id variable id_cross  
read_csv_with_filename <- function(csv_path) {
  df <- read_csv(csv_path) %>%
    mutate(filename = csv_path, id_cross = paste0(id2, filename))
  return(df)
}

# import all csvs to a single df
raw_join_df <- do.call(rbind, lapply(raw_comment_files, read_csv_with_filename))

# generate a hash to uniquely identify each comment over time (assuming no edits to the comment content)

raw_join_df$comment_hash <- character(length = nrow(raw_join_df))

for (i in 1:nrow(raw_join_df)) {
  raw_join_df$comment_hash[i] <- sha1(paste(raw_join_df$filename[i], 
                                             raw_join_df$user[i],
                                             raw_join_df$id2[i],
                                             raw_join_df$id_par2[i],
                                             raw_join_df$comment[i],
                                             raw_join_df$entry[i],
                                             sep = '_'))
}

dim(raw_join_df)
raw_join_df$id_cross  <- raw_join_df$comment_hash
# old test cut -- NOT RUN

df = read_csv('data/Futurology/data_aq5sih.post.dynamic.csv')
df2 = read_csv('data/Futurology/data_aq5sih.comments.csv')

df2  <- raw_join_df

extract_postcode  <- function(filename) {
    postcode  <-   str_extract(filename, pattern = '_[[:alnum:]]*') %>% str_sub(start=2)
}

extract_subreddit  <- function(filename) {
    ifelse(grepl(x=filename, pattern='Futurology'), 'Futurology', 'KotakuInAction')
}

df2  <- df2 %>% ungroup() %>%
        mutate(subreddit = extract_subreddit(filename), postcode = extract_postcode(filename))

colnames(df2)
post_count <- df2 %>% filter(id2 == 1) %>% distinct() %>% summarize(post_count = n())
comment_count <- df2 %>% filter(id2 > 1) %>% distinct() %>% summarize(comment_count = n())

```

# Basic stats

There are `r length(unique(df2$id_cross))` comments and posts in the data. 
This includes `r post_count` posts and `r comment_count` comments.   
Why are these numbers different?

# Controversiality data from the Reddit API

```{r explore-controversiality_variable}

# to sort comments by controversiality


# get controversial comments
controversial_ids  <- df2 %>% select(id_cross, controversiality) %>% 
    filter(controversiality == 1)


# get non-controversial comments
noncontrov_ids  <-  df2 %>% select(id_cross, controversiality) %>% 
    filter(!(id_cross %in% controversial_ids$id_cross), controversiality == 0)

#proportion of controversial comments

controversial_prop <- length(unique(controversial_ids$id_cross))/length(unique(df2$id_cross))   

```

The proportion of posts or comments marked as controversial sometime in their lifetime is `r controversial_prop*100`%.
This seems really high. We might need to check the data on this. 

Over what time period do posts become controversial?

```{r explore-controversiality2}

# select all the comments marked as controversial
controvs  <- df2 %>% filter(id_cross %in% controversial_ids$id_cross) %>%
    group_by(id_cross) %>% arrange(id_cross, time)

controv_summary  <- controvs %>% group_by(id_cross) %>%
    summarize(score_range = max(comment_score)-min(comment_score),
             time_range = max(time) - min(time) ) %>%
             arrange(desc(score_range), time_range)

controv_summary %>% summarize(m = max(score_range))
controv_summary %>% ggplot(aes(score_range)) + geom_histogram(bins=100) +
    xlab('Change in score over time of harvest') +
    ggtitle('Range of scores for comments with controversiality')

controv_summary %>% ggplot(aes(y=score_range, x=time_range)) + geom_jitter() +
    labs(x = 'Time range (hours)', y = 'Score range (votes?)') +
    ggtitle('Range of scores vs time range for comments with controversiality')

# select all non-controversial posts

noncontrovs  <- df2 %>% filter(id_cross %in% noncontrov_ids$id_cross) %>%
    group_by(id_cross) %>% arrange(id_cross, time)

noncontrov_summary  <- noncontrovs %>% group_by(id_cross) %>%
    summarize(score_range = max(comment_score)-min(comment_score),
             time_range = max(time) - min(time) ) %>%
             arrange(desc(score_range), time_range)

noncontrov_summary %>% summarize(m = max(score_range))
noncontrov_summary %>% ggplot(aes(score_range)) + geom_histogram(bins=100) +
    xlab('Change in score over time of harvest') +
    ggtitle('Range of scores for comments with no controversiality')

noncontrov_summary %>% ggplot(aes(y=score_range, x=time_range)) + geom_jitter() +
    labs(x = 'Time range (hours)', y = 'Score range (votes?)') +
    ggtitle('Range of scores vs time range for comments with no controversiality')


```

It's hard to see much in the first plot, but it does seem that most controversial posts don't have very dynamic comment scores.   

```{r compare-controv-noncontrov}

# combining the data for controversial and non-controversial 
noncontrov_summary['becomes_controv']  <-  FALSE
controv_summary['becomes_controv']  <-  TRUE
connoncon_summary  <-  rbind(noncontrov_summary, controv_summary)

# combining the data for controversial and non-controversial 
noncontrovs['becomes_controv']  <-  FALSE
controvs['becomes_controv']  <-  TRUE
connoncon  <-  rbind(noncontrovs, controvs)
colnames(connoncon)

connoncon_summary %>% ggplot(aes(y=score_range, x=time_range,
    colour = becomes_controv, group = becomes_controv)) +
    geom_jitter() +
    labs(x = 'Time range (hours)', y = 'Score range (votes?)') +
    ggtitle('Range of scores vs time range for comments')

comparedf  <- df2 %>% group_by(id_cross) %>%
    mutate(becomes_controversial = ifelse(controversiality == 1, TRUE, FALSE)) %>%
    group_by(becomes_controversial) %>% summarize(score_range = max(comment_score)-min(comment_score),
             time_range = max(time) - min(time) )

```

The plot above could mean that `controversiality` does not do much. Or it could mean that the low comment-score range of comments marked controversiality is a result of downvotes substracted from upvotes. 


```{r controversiality-entry}

df2 %>% select(id_cross, entry, filename) %>%
    ggplot(aes(x=entry, group = filename, fill = filename)) + geom_density() +
    labs(x = 'entry time (hours into the gather)') + 
    theme(legend.position="none") +
    ggtitle('Entry times for comments grouped by threads')

write.csv(connoncon, 'rawdata_frame.csv')
df  <- read_csv('rawdata_frame.csv')
connoncon  <- read_csv('rawdata.zip')
colnames(connoncon)
```

Most of the comments come near the beginning of the collection of threads.

## Problems and tasks with the data
- How to correct for the arbitrary startpoint of the data capture 
- How soon after its entry does a comment become controversial?
- Does a controversial comment ever become non-controversial?
- how is controversiality distributed across threads?
- how does controversiality different between subreddits?

```{r controversiality_thread}

connoncon  <- connoncon %>% ungroup() %>%
        mutate(subreddit = extract_subreddit(filename), postcode = extract_postcode(filename))

connoncon %>% group_by(subreddit, postcode) %>%
   summarize(controvcount = sum(becomes_controv)) %>%
   ggplot(aes(x=postcode, fill = subreddit, y=controvcount)) +
        geom_col() +
        coord_flip() +
        ggtitle('Numbers of controversial comments per post')

```

There is no great difference between the subreddits, but great differences between different posts.

# Text analysis at late stage

```{r textexplore}
library(quanteda)
library(readr)
library(tidyverse)

if (!exists(connonon))
    connoncon  <- read_csv('rawdata.zip')

co  <- corpus(connoncon, text_field = 'comment', docid_field = 'id_cross')

ntype(co)

names(docvars(co))

dfm  <-  dfm(co, remove_punct = TRUE, stem =  FALSE, tolower = TRUE, remove = stopwords('english'))
kwic(co, 'ai') %>% head()
textplot_xray(kwic(co, 'ai'))

summary(co)
textstat_dist(dfm)
readable  <- textstat_readability(x = co, measure = 'Flesch.Kincaid')
ggplot(readable, aes(Flesch.Kincaid)) +
    geom_histogram(bins = 100) +
    facet_grid(becomes_controv ~.) +
    ggtitle('Comment readability scores')  

#trying to add readability as a variable, but rows don't match
rdf  <- data.frame(id_cross = readable$document, readable = readable$Flesch.Kincaid)


# try a left join to add readability
colnames(connoncon2)
connoncon2  <- left_join(x = connoncon, y = rdf, by = 'id_cross') 



connoncon2 %>%
    select(id_cross, subreddit, readable, comment_score, becomes_controv ) %>%
    ggplot(aes(y = comment_score, x =readable)) +
    geom_jitter() +
    facet_grid(subreddit~.)+
    ggtitle('Comment scores vs readability')

```

Isn't that strange? High comment scores often have low readability? I guess the topic is more important than its readability?

summary(readable)
summary(dfm)
summary(corpus)

futur  <- corpus_subset(co, subreddit = 'Futurology')
docvars(co) %>% head

```

