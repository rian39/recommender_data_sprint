"","id2","user","time","entry","id_par2","comment_score","controversiality","comment"
"1",1,"izumi3682",1,1,1,999,999,"x"
"2",2,"izumi3682",1,1,1,1,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does not deem important. Perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect that the human mind, limited by biology can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"3",2,"izumi3682",2,1,1,1,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"4",2,"izumi3682",3,1,1,3,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"5",2,"izumi3682",4,1,1,5,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"6",3,"SoulWart",4,4,2,1,0,"I enjoyed your comment more than the article."
"7",4,"PleaseOpenABook",4,4,2,1,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"8",2,"izumi3682",5,1,1,6,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"9",3,"SoulWart",5,4,2,1,0,"I enjoyed your comment more than the article."
"10",4,"PleaseOpenABook",5,4,2,1,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"11",5,"izumi3682",5,5,4,1,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"12",2,"izumi3682",6,1,1,8,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"13",3,"SoulWart",6,4,2,2,0,"I enjoyed your comment more than the article."
"14",4,"PleaseOpenABook",6,4,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"15",5,"izumi3682",6,5,4,1,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"16",2,"izumi3682",7,1,1,10,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"17",3,"SoulWart",7,4,2,5,0,"I enjoyed your comment more than the article."
"18",4,"PleaseOpenABook",7,4,2,1,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"19",5,"izumi3682",7,5,4,2,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"20",6,"pixl_graphix",7,7,4,1,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"21",2,"izumi3682",8,1,1,11,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"22",3,"SoulWart",8,4,2,6,0,"I enjoyed your comment more than the article."
"23",4,"PleaseOpenABook",8,4,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"24",5,"pixl_graphix",8,5,4,1,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"25",6,"izumi3682",8,7,4,2,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"26",2,"izumi3682",9,1,1,14,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"27",3,"SoulWart",9,4,2,6,0,"I enjoyed your comment more than the article."
"28",4,"RationalParadigm",9,4,2,1,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"29",7,"PleaseOpenABook",9,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"30",8,"pixl_graphix",9,9,7,5,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"31",9,"izumi3682",9,9,7,3,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"32",2,"izumi3682",10,1,1,14,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"33",3,"SoulWart",10,4,2,5,0,"I enjoyed your comment more than the article."
"34",4,"RationalParadigm",10,4,2,1,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"35",7,"PleaseOpenABook",10,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"36",8,"pixl_graphix",10,9,7,5,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"37",9,"izumi3682",10,9,7,4,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"38",2,"izumi3682",11,1,1,14,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"39",3,"SoulWart",11,4,2,4,0,"I enjoyed your comment more than the article."
"40",4,"RationalParadigm",11,4,2,1,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"41",7,"PleaseOpenABook",11,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"42",8,"pixl_graphix",11,9,7,5,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"43",9,"izumi3682",11,9,7,4,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"44",2,"izumi3682",12,1,1,17,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"45",3,"SoulWart",12,4,2,4,0,"I enjoyed your comment more than the article."
"46",4,"RationalParadigm",12,4,2,2,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"47",7,"PleaseOpenABook",12,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"48",8,"pixl_graphix",12,9,7,7,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"49",9,"izumi3682",12,9,7,3,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"50",2,"izumi3682",13,1,1,16,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"51",3,"SoulWart",13,4,2,5,0,"I enjoyed your comment more than the article."
"52",4,"RationalParadigm",13,4,2,2,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"53",7,"PleaseOpenABook",13,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"54",8,"pixl_graphix",13,9,7,6,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"55",9,"izumi3682",13,9,7,4,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"56",2,"izumi3682",14,1,1,17,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"57",3,"SoulWart",14,4,2,5,0,"I enjoyed your comment more than the article."
"58",4,"RationalParadigm",14,4,2,2,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"59",7,"PleaseOpenABook",14,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"60",8,"pixl_graphix",14,9,7,6,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"61",9,"izumi3682",14,9,7,5,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"62",2,"izumi3682",15,1,1,16,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"63",3,"SoulWart",15,4,2,5,0,"I enjoyed your comment more than the article."
"64",4,"RationalParadigm",15,4,2,2,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"65",7,"PleaseOpenABook",15,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"66",8,"pixl_graphix",15,9,7,7,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"67",9,"izumi3682",15,9,7,4,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"68",2,"izumi3682",16,1,1,15,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"69",3,"SoulWart",16,4,2,5,0,"I enjoyed your comment more than the article."
"70",4,"RationalParadigm",16,4,2,2,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"71",7,"PleaseOpenABook",16,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"72",8,"pixl_graphix",16,9,7,6,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"73",9,"izumi3682",16,9,7,4,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"74",2,"izumi3682",17,1,1,16,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"75",3,"SoulWart",17,4,2,5,0,"I enjoyed your comment more than the article."
"76",4,"RationalParadigm",17,4,2,2,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"77",7,"PleaseOpenABook",17,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"78",8,"pixl_graphix",17,9,7,6,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"79",9,"izumi3682",17,9,7,4,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
"80",2,"izumi3682",18,1,1,15,0,"All biology either sleeps or rests. Even bacteria. Plants reduce activity at cyclical times. The jellyfish and the tiny round worm become somnolent. Even the simplicity of ""awareness"" seems to require downtime.

Once you get into conscious vertebrates sleep is essential. All vertebrates sleep. Including mammals, including humans.

It was once believed the reason for sleep was to restore energy and allow cells to rest and regenerate, but the latest scholarship seems to demonstrate that for vertebrates at least, sleep is essential because we take in far and away more information than we need. In short we need to sleep because it is *fatal* to stay conscious for too long. It appears that when we sleep that the brain goes thru some physical changes of waste cleaning and solidifying memories our biology deems important and removing memories that our biology does *not* deem important. We can consciously control that to some extent. But perhaps too much additional information just mucks up the focus.

But that is just the limitations of biology. *Computing* is a whole other ballgame.


 An AI has computing power behind it that might nullify the need for ""sleep"" at all. Just think of the continuous information it takes in as something like a hyperdimensional aspect of reality that the human mind, limited by biology, can't perceive. And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable  and incomprehensible to human minds.

This is why, if we want a ""human friendly"" Technological Singularity, we must work more towards merging our biological minds with our computing. If the computing and AI development remains external from our minds, it's just gonna outstrip us. In about 5 years probably.

I used to think that all of this happening by the year, say, 2025 was wildest fantasy. That the realistic date was closer to Ray Kurzweil's 2045.  But since the year 2015, I am starting to move that date up to about 2030.

But some of these developments in the last few *weeks* are making me wonder if it may go out of control as early as the year 2025.  I stick for now with my forecast of 2030-35 for the technological singularity in one way or another. But just within the last few months I have started to wonder if I am simply not thinking exponentially enough.

I read an article the other day that said while ""Moore's Law"" is coming to an end a new ""Law"" is coming to take it's place and even probably to transcend it. You can call it the ""Moore's Law of AI"".

https://www.eetimes.com/document.asp?doc_id=1333471


It's impact will be just as exponential. Ray Kurzweil's curve of computing capability continues unabated and if anything starts to become the dreaded ""Al Gore hockey stick"". And everybody knows what *that* looks like.

"
"81",3,"SoulWart",18,4,2,4,0,"I enjoyed your comment more than the article."
"82",4,"RationalParadigm",18,4,2,2,0,"From what I understand GPUs have picked up after CPUs in relation to Moore's Law, so it's only dead by name.

&amp;#x200B;

We're also actively researching neuromorphic chips, and making strides in quantum computing. Hardware is unlikely to be a bottleneck for the foreseeable future."
"83",7,"PleaseOpenABook",18,9,2,0,0,"&gt; And this is one of the reasons that I wonder that our continued development of AI and AGI probably will result in sentience and intelligence that is unimaginable and incomprehensible to human minds.

How can a bunch of copper wires, memory chips, and silicon circuits develop something as biological as sentience?"
"84",8,"pixl_graphix",18,9,7,7,0,"""How can a bunch of water, meat, and chemicals develop something as crystalmorphic as sentience?"" --Xzzgy from Glorbor 9

"
"85",9,"izumi3682",18,9,7,3,0,"I think the trick will be getting algorithms that are separate to communicate with each other. How we would do that, I don't know. But take a look at this and see what you think.

https://www.reddit.com/user/izumi3682/comments/9786um/but_whats_my_motivation_artificial_general/"
